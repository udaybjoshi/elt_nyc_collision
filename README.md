# ETL Pipeline for NYC Motor Vehicle Collisions Data

## Project Description
The **ETL Pipeline for NYC Motor Vehicle Collisions Data** is a Python-based application designed to automate the extraction, transformation, and loading (ETL) process for traffic collision data from the NYC Open Data API. The pipeline processes data about motor vehicle collisions, injuries, fatalities, and vehicle types, storing the results in an MySQL database for analysis and reporting.

## Business Context
The NYC Collision Data project aims to analyze vehicle collisions in New York City to **improve public safety, optimize city planning, and support research efforts** by leveraging insights from historical collision data. The data includes information on crash dates, times, locations, contributing factors, and the severity of incidents.

## Business Goals
### 1. Public Safety:
- Identify high-risk areas (collision hotspots) to focus safety measures.
- Analyze trends in the severity of collisions (injuries and fatalities).
- Determine common contributing factors to collisions to inform public awareness campaigns.
### 2. City Planning:
- Use location-based collision data to recommend infrastructure improvements (e.g., road repairs, traffic lights).
- Understand pedestrian and cyclist safety concerns to guide the allocation of bike lanes and crosswalks.
### 3. Policy and Law Enforcement:
- Identify patterns related to time of day, weather conditions, and other factors that lead to accidents.
- Evaluate the effectiveness of existing traffic laws and propose necessary adjustments.
### 4. Research and Reporting:
- Create public-facing dashboards and periodic reports for stakeholders (e.g., city officials, law enforcement, and researchers).
- Share insights with insurance companies, urban developers, and NGOs.

## ðŸ“‚ Project Folder Structure
etl_nyc_collision/ â”‚â”€â”€ config/ # Configuration files (e.g., environment variables, database settings) â”‚ â”œâ”€â”€ database_config.yml # Database connection details â”‚ â”œâ”€â”€ logging_config.yml # Logging settings â”‚ â”œâ”€â”€ env.example # Example of environment variables file (.env is used but not committed) â”‚ â”‚â”€â”€ data/ # Data storage folder â”‚ â”œâ”€â”€ input/ # Raw input data (CSV, JSON, etc.) â”‚ â”‚ â”œâ”€â”€ raw_api_data.csv # Raw collision data from external API â”‚ â”‚ â”œâ”€â”€ sample_data.csv # Sample data for testing â”‚ â”‚ â”‚ â”œâ”€â”€ output/ # Processed/cleaned data ready for analysis â”‚ â”‚ â”œâ”€â”€ cleaned_api_data.csv # Preprocessed collision data â”‚ â”‚ â”œâ”€â”€ transformed_data.csv # Transformed data ready for MySQL insertion â”‚ â”‚â”€â”€ logs/ # Logs for ETL pipeline runs â”‚ â”œâ”€â”€ source_pipeline.log # Logs for raw data extraction â”‚ â”œâ”€â”€ staging_pipeline.log # Logs for data transformation & staging â”‚ â”œâ”€â”€ entities_pipeline.log # Logs for final data transfer â”‚ â”‚â”€â”€ scripts/ # ETL scripts and analysis functions â”‚ â”œâ”€â”€ run_source.py # Extract and load raw data into MySQL source table â”‚ â”œâ”€â”€ run_staging.py # Process and move data from source to staging table â”‚ â”œâ”€â”€ run_entities.py # Load validated data into the final entities table â”‚ â”œâ”€â”€ transform.py # Data transformation logic â”‚ â”œâ”€â”€ analysis.py # Visualizations and analytics on processed data â”‚ â”œâ”€â”€ create_views.sql # SQL scripts to create database views â”‚ â”‚â”€â”€ tests/ # Unit tests for pipeline validation â”‚ â”œâ”€â”€ test_source.py # Tests for raw data extraction â”‚ â”œâ”€â”€ test_staging.py # Tests for staging transformation â”‚ â”œâ”€â”€ test_entities.py # Tests for final data transfer â”‚ â”‚â”€â”€ notebooks/ # Jupyter Notebooks for exploratory data analysis (EDA) â”‚ â”œâ”€â”€ eda.ipynb # Initial exploratory analysis of collision data â”‚ â”‚â”€â”€ requirements.txt # Python dependencies â”‚â”€â”€ .gitignore # Ignore unnecessary files (e.g., .env, logs, data files) â”‚â”€â”€ README.md # Project documentation

## Features
- **Data Source**: Extracts live collision data from the [NYC Open Data API](https://data.cityofnewyork.us/resource/h9gi-nx95.json).
- **Transformation**: Cleans, validates, and enriches the data.
- **Database Integration**: Loads the processed data into a MySQL database.
- **Logging**: Tracks the ETL process in log files for monitoring and debugging.
- **Modular Design**: Divides the pipeline into reusable components for scalability.

## Prerequisites
Before running the project, ensure you have:
- **Python 3.8 or higher**
- **MySQL Server** (8.0+ recommended) 
- **Git** installed on your system
- Python libraries listed in `requirements.txt`

## Installation and Setup

### 1. Install MySQL
- Download MySQL: [https://dev.mysql.com/downloads/](https://dev.mysql.com/downloads/)
- Follow the installation instructions for your operating system.
- Configure MySQL with a user and password for this project.

### 2. Clone the Repository
Clone the repository to your local machine:
```bash
git clone https://github.com/udaybjoshi/etl_nyc_collision.git
cd etl_nyc_collision
```

### 3. Set Up the Virtual Environment and Install Dependencies
```bash
python -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 4. Configure Database
- Log in to MySQL:
```bash
mysql -u root -p
```
- Create a new database in MySQL
```bash 
CREATE DATABASE nyc_collision;
```
- Switch to the `nyc_collision` database:
```bash
USE nyc_collision
```

- Update the .env file with the database credentials:
```bash
DB_NAME = nyc_collision
DB_USER = root
DB_PASSWORD = your_password
DB_HOST = localhost
DB_PORT = 3306
```

### 5. Run the ETL Pipeline
- Execute the main ETL script:
```bash
python scripts/etl_pipeline.py
```

### 6. Test the Pipeline
- Run unit tests:
```bash
python -m pytest tests/test_etl.py --disable-warnings
```

### 7. View Logs
- Check logs for pipeline execution in `logs/etl_log.txt`

## Database Configuration
The database connection details are stored in the `config/db_config.py` file. This script reads credentials from the `.env` file and establishes a connection to the MySQL database.

## Notes
- Make sure the MySQL service is running before executing the ETL pipeline.
- If you encounter connection issues, verify the `.env` file and database settings.

## Licence
This project is licensed under the MIT License - see the LICENSE file for details.



